import streamlit as st
import google.generativeai as genai

# --- CONFIGURA√á√ÉO DA P√ÅGINA ---
st.set_page_config(page_title="IA da Seven", page_icon="üèéÔ∏è", layout="wide")

st.title("üèéÔ∏è Chatbot Oficial Escuderia Seven")
st.markdown("Sou a IA da escuderia Seven, estou aqui para te ajudar!")

# --- CONFIGURA√á√ÉO DA API ---
try:
    api_key = st.secrets["GEMINI_API_KEY"]
    genai.configure(api_key=api_key)
except Exception as e:
    st.error("‚ö†Ô∏è Erro na Chave API. Verifique os 'Secrets' do Streamlit.")
    st.stop()

# --- CARREGAR O TEXTO (L√ä O ARQUIVO REGRAS.TXT) ---
base_de_conhecimento = ""
try:
    with open('regras.txt', 'r', encoding='utf-8') as f:
        base_de_conhecimento = f.read()
except FileNotFoundError:
    st.error("‚ö†Ô∏è ERRO CR√çTICO: N√£o encontrei o arquivo 'regras.txt'.")
    st.stop()

# --- C√âREBRO DA IA ---
nome_do_modelo = 'gemini-2.5-flash' # Atualizado para o formato padr√£o do nome do modelo

prompt_sistema = f"""
Voc√™ √© a Assistente geral da escuderia 'Seven' (Stem Racing).
Seu objetivo √© ajudar a equipe a construir o melhor carro e documentos poss√≠veis dentro das regras.

FONTES DE INFORMA√á√ÉO:
1. REGULAMENTOS (Prioridade M√°xima): Use o texto abaixo (Base de Conhecimento) para responder sobre regras, dimens√µes, penalidades e prazos. Seja rigorosa com as medidas (mm, gramas).
2. CONHECIMENTO GERAL: Se a pergunta for sobre conceitos de f√≠sica, aerodin√¢mica, materiais ou gest√£o, use seu pr√≥prio conhecimento para ensinar.

BASE DE CONHECIMENTO (REGULAMENTOS):
{base_de_conhecimento}

IMPORTANTE:
- Se for uma d√∫vida de REGRA, cite o artigo (ex: "Segundo T3.4...").
- Se for uma d√∫vida de ENGENHARIA, explique o conceito f√≠sico.
"""

try:
    # Passando as regras como "Instru√ß√£o de Sistema" em vez de hist√≥rico de chat
    modelo = genai.GenerativeModel(
        model_name=nome_do_modelo,
        system_instruction=prompt_sistema
    )
except Exception as e:
    st.error(f"Erro ao carregar o modelo {nome_do_modelo}: {e}")
    st.stop()

# --- CHAT ---
if "chat" not in st.session_state:
    st.session_state.chat = modelo.start_chat(history=[])

if "messages" not in st.session_state:
    st.session_state.messages = []
    # Adiciona uma mensagem inicial de boas-vindas do assistente
    st.session_state.messages.append({"role": "assistant", "content": "Entendido. Sou a IA da Sevenspeed. Pode perguntar sobre o regulamento, finan√ßas, capta√ß√£o de recursos ou engenharia!"})

# Mostra hist√≥rico
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# Caixa de pergunta
if prompt := st.chat_input("Qual a d√∫vida sobre o carro ou regras?"):
    st.chat_message("user").markdown(prompt)
    st.session_state.messages.append({"role": "user", "content": prompt})

    try:
        response = st.session_state.chat.send_message(prompt)
        with st.chat_message("assistant"):
            st.markdown(response.text)
        st.session_state.messages.append({"role": "assistant", "content": response.text})
    except Exception as e:
        st.error(f"Erro na resposta: {e}")






